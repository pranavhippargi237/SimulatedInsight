# ED Bottleneck Engine - Real-Time MVP

A natural-language-first system for detecting, simulating, and optimizing Emergency Department (ED) bottlenecks in real-time.

## ğŸ¯ Overview

The ED Bottleneck Engine empowers hospital operations teams to:
- **Detect bottlenecks** in real-time using queueing models and anomaly detection
- **Simulate scenarios** using natural language queries (e.g., "What if we add two nurses during peak hours?")
- **Optimize operations** with AI-powered suggestions based on constraints

**MVP Success Metrics**:
- Simulations complete in <10s
- Real-time metrics update every 5s
- Bottleneck detection sensitivity >85%
- 90% natural-language query parsing accuracy

## ğŸ—ï¸ Architecture

```
Frontend (React) â†’ API Gateway (FastAPI) â†’ Core Engines
                                         â”œâ”€â”€ Bottleneck Detector
                                         â”œâ”€â”€ Simulation Engine (SimPy)
                                         â””â”€â”€ Optimization Layer
                                         
Data Flow: ClickHouse (OLAP) + Redis (Cache)
```

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- Python 3.11+ (for local development)
- Node.js 18+ (for local frontend development)
- OpenAI API key (optional, for enhanced NLP parsing)

### Running with Docker Compose

1. **Clone and navigate to the project**:
   ```bash
   cd "Simulated Insights"
   ```

2. **Set environment variables** (optional):
   ```bash
   export OPENAI_API_KEY=your_key_here
   ```

3. **Start all services**:
   ```bash
   docker-compose up --build
   ```

4. **Access the application**:
   - Frontend: http://localhost:3000
   - API Docs: http://localhost:8000/docs
   - ClickHouse: http://localhost:8123

### Local Development

#### Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Start ClickHouse and Redis (via Docker)
docker-compose up clickhouse redis -d

# Run the API
uvicorn app.main:app --reload --port 8000
```

#### Frontend

```bash
cd frontend
npm install
npm run dev
```

## ğŸ“Š Data Ingestion

### Generate Sample Data

```bash
cd backend
python generate_sample_data.py
# Creates sample_data.csv with 1000 synthetic events
```

### Upload Data

1. **Via Frontend**: Use the Chat page â†’ "Upload CSV Data" button
2. **Via API**:
   ```bash
   curl -X POST "http://localhost:8000/api/ingest/csv" \
     -F "file=@sample_data.csv"
   ```

### CSV Format

```csv
timestamp,event_type,patient_id,stage,resource_type,resource_id,duration_minutes
2024-01-15T10:30:00Z,arrival,anon_patient_123,triage,,,
2024-01-15T10:35:00Z,triage,anon_patient_123,triage,nurse,nurse_1,5.0
```

## ğŸ® Usage

### Natural Language Queries

Use the **Chat** page to ask questions in plain English:

- "What if we add two nurses during peak hours on weekends?"
- "Simulate adding a triage nurse from 2-6 PM"
- "What happens if we add one doctor on Saturday?"

The system will:
1. Parse your query into a structured scenario
2. Run a discrete-event simulation
3. Show predicted impacts on DTD, LOS, and LWBS

### Dashboard

The **Dashboard** shows:
- Real-time KPIs (DTD, LOS, LWBS, Bed Utilization)
- Historical trends with anomaly alerts
- Detected bottlenecks with root causes and recommendations

### History

The **History** page tracks all simulations with export to CSV.

## ğŸ”Œ API Endpoints

### Health Check
```bash
GET /api/health
```

### Ingest Data
```bash
POST /api/ingest/csv
POST /api/ingest/json
```

### Get Metrics
```bash
GET /api/metrics?window=24h&include_anomalies=true
```

### Detect Bottlenecks
```bash
POST /api/detect?window_hours=24&top_n=3
```

### Run Simulation
```bash
POST /api/simulate
POST /api/simulate/nlp  # Natural language input
```

### Optimize
```bash
POST /api/optimize
```

See full API documentation at http://localhost:8000/docs

## ğŸ§ª Testing

```bash
cd backend
pytest tests/ -v --cov=app
```

## ğŸ“ Project Structure

```
ed-bottleneck-engine/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ core/          # Detection, simulation, optimization, NLP
â”‚   â”‚   â”œâ”€â”€ data/          # Ingestion, schemas, storage
â”‚   â”‚   â”œâ”€â”€ routers/       # API endpoints
â”‚   â”‚   â””â”€â”€ main.py        # FastAPI app
â”‚   â”œâ”€â”€ tests/             # Test suite
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/   # React components
â”‚   â”‚   â”œâ”€â”€ pages/         # Dashboard, Chat, History
â”‚   â”‚   â””â”€â”€ services/      # API client
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

Environment variables (set in `.env` or docker-compose):

- `OPENAI_API_KEY`: For enhanced NLP parsing (optional)
- `CLICKHOUSE_HOST`: ClickHouse host (default: localhost)
- `REDIS_HOST`: Redis host (default: localhost)
- `CORS_ORIGINS`: Allowed CORS origins

## ğŸ“ˆ Performance

- **Simulation**: <10s for 100 Monte Carlo iterations
- **Detection**: <5s for 24h window analysis
- **Metrics**: Real-time updates every 5s
- **Cache**: Redis TTL = 1 hour (bottlenecks), 5s (metrics)

## ğŸ› ï¸ Extending

### Add New ED Stage

1. Update `EDSimulation` in `backend/app/core/simulation.py`
2. Add stage to `PatientGenerator.process_patient()`
3. Update detection logic in `BottleneckDetector`

### Custom NLP Parsing

Modify `backend/app/core/nlp.py` to add domain-specific parsing rules.

## ğŸ“ License

MIT License

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“§ Support

For issues or questions, please open a GitHub issue.

---

**Built with**: FastAPI, React, SimPy, ClickHouse, Redis, OpenAI

